{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# import all the libraries that you need at the top of the notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import f_regression, SelectPercentile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, BaggingRegressor, StackingRegressor\n",
    "import joblib\n",
    "from sklearn.svm import SVR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:29:03.191558Z",
     "end_time": "2023-08-25T00:29:03.210044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Define BUCKET_ROOT (for now a dummy value will do, this will become clear in Part 3)\n",
    "BUCKER_ROOT = 'dummy'\n",
    "# Define DATA_DIR (initially this will be a local directory, but later it will be a Google Cloud Storage bucket)\n",
    "DATA_DIR = './'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:29:03.206105Z",
     "end_time": "2023-08-25T00:29:03.293334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# helper methods for dataset loading\n",
    "def categorize_price(price):\n",
    "    if price == 0:\n",
    "        return \"FREE\"\n",
    "    elif 0 < price < 5.0:\n",
    "        return \"CHEAP\"\n",
    "    else:\n",
    "        return \"EXPENSIVE\"\n",
    "\n",
    "def remove_outliers(df,columns,n_std):\n",
    "    for col in columns:\n",
    "\n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "\n",
    "        df = df[(df[col] <= mean+(n_std*sd))]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# the method below will return the data transformed, standarized, outliers removed, and feature engineered\n",
    "def load_data(data_dir):\n",
    "    apps = pd.read_csv(data_dir)\n",
    "    apps['Reviews'] = pd.to_numeric(apps['Reviews'], errors='coerce')\n",
    "    apps['Size'] = apps['Size'].apply(lambda x: float(x.replace('k','')) / 1024 if 'k' in str(x) else x)  # Convert k to M\n",
    "    apps['Size'] = apps['Size'].apply(lambda x: None if x == 'Varies with device' else x) # Handles \"Varies with device\" values\n",
    "    apps['Size'] = apps['Size'].str.replace('M', '').str.replace('k', '').astype(float)\n",
    "    apps['Installs'] = apps['Installs'].str.replace('+', '').str.replace(',', '').astype('int64')\n",
    "    apps['Price'] = apps['Price'].str.replace('$', '').astype(float)\n",
    "    apps['Last Updated'] = pd.to_datetime(apps['Last Updated'])\n",
    "    apps = apps.drop_duplicates(subset='App', keep='first')\n",
    "    apps = remove_outliers(apps, ['Price'], 3)\n",
    "    apps = apps.dropna(subset=['Rating'])\n",
    "    apps['Size'] = apps['Size'].fillna(0)\n",
    "    encoder = LabelEncoder()\n",
    "    apps['Category_Encoded'] = encoder.fit_transform(apps['Category'])\n",
    "    apps['Content Rating_Encoded'] = encoder.fit_transform(apps['Content Rating'])\n",
    "    apps['Android Ver_Encoded'] = encoder.fit_transform(apps['Android Ver'])\n",
    "    current_date = pd.to_datetime('2019-01-01')  # All data is from before 2019\n",
    "    apps['Time Since Last Update'] = (current_date - apps['Last Updated']).dt.days\n",
    "    apps['App_Name_Length'] = apps['App'].apply(len)\n",
    "    apps['Price_Category_Labels'] = apps['Price'].apply(categorize_price)\n",
    "    apps['Price_Category_Encoded'] = apps['Price_Category_Labels'].map({'FREE': 0, 'CHEAP': 1, 'EXPENSIVE': 2})\n",
    "    numeric_columns = apps.select_dtypes(include=['number'])\n",
    "    numeric_columns = numeric_columns.drop(['Price'], axis=1)\n",
    "    apps = apps[numeric_columns.columns]\n",
    "    scaler = StandardScaler()\n",
    "    numeric_columns = ['Reviews', 'Size', 'Installs', 'Category_Encoded', 'Content Rating_Encoded','Android Ver_Encoded', 'Time Since Last Update', 'App_Name_Length', 'Price_Category_Encoded']\n",
    "    apps[numeric_columns] = scaler.fit_transform(apps[numeric_columns])\n",
    "    selector = SelectPercentile(score_func=f_regression, percentile=80)\n",
    "    X = selector.fit_transform(apps.select_dtypes(include=np.number), apps.Rating)\n",
    "    best_features = selector.get_support(indices=True)\n",
    "    apps = apps.select_dtypes(include=np.number).iloc[:, best_features]\n",
    "    return apps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:29:03.229645Z",
     "end_time": "2023-08-25T00:29:03.294363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    apps = data\n",
    "    x = apps.drop('Rating', axis=1)\n",
    "    y = apps.Rating\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "    return x_train, x_test, y_train, y_test, x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:29:03.252544Z",
     "end_time": "2023-08-25T00:29:03.295401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_test, y_test, type): #type can either be 'voting' or 'bagging' or 'stacking'\n",
    "    if type == 'voting':\n",
    "        rf_model = RandomForestRegressor(n_estimators=93)\n",
    "        tree_model = DecisionTreeRegressor(max_leaf_nodes=15)\n",
    "        gradboost_model = GradientBoostingRegressor(max_depth=5, n_estimators=30)\n",
    "\n",
    "        ensemble = VotingRegressor(\n",
    "            estimators=[('rf', rf_model),\n",
    "                        ('tree', tree_model),\n",
    "                        ('gradboost', gradboost_model)]\n",
    "        )\n",
    "        ensemble.fit(x_train, y_train)\n",
    "        for name, model in ensemble.named_estimators_.items():\n",
    "            print(f'{name} = {model.score(x_test, y_test)}')\n",
    "        print(f\"voting ensemble score: {ensemble.score(x_test, y_test)}\")\n",
    "        return ensemble\n",
    "    elif type == 'bagging':\n",
    "\n",
    "        ensemble = BaggingRegressor(DecisionTreeRegressor(),\n",
    "                                    n_estimators=500, max_samples=100,\n",
    "                                    n_jobs= -1, random_state=42)\n",
    "        ensemble.fit(x_train, y_train)\n",
    "        print(f\"bagging ensemble score: {ensemble.score(x_test, y_test)}\")\n",
    "        return ensemble\n",
    "    elif type == 'stacking':\n",
    "        rf_model = RandomForestRegressor(n_estimators=93)\n",
    "        tree_model = DecisionTreeRegressor(max_leaf_nodes=15)\n",
    "        gradboost_model = GradientBoostingRegressor(max_depth=5, n_estimators=30)\n",
    "        svr_model = SVR(kernel='linear')\n",
    "\n",
    "        ensemble = StackingRegressor(\n",
    "            estimators=[('rf', rf_model),\n",
    "                        ('tree', tree_model),\n",
    "                        ('gradboost', gradboost_model)],\n",
    "            final_estimator=svr_model, n_jobs=-1, cv=5\n",
    "        )\n",
    "        ensemble.fit(x_train, y_train)\n",
    "        print(f\"stacking ensemble score: {ensemble.score(x_test, y_test)}\")\n",
    "    else:\n",
    "        raise Exception(\"type parameter should be either 'voting', 'bagging' or 'stacking'\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:29:03.271340Z",
     "end_time": "2023-08-25T00:29:03.295919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def save_model(model, type):\n",
    "    path = f'{DATA_DIR}/model_artifacts/model_{type}.joblib'\n",
    "    joblib.dump(model, path)\n",
    "    return path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:29:03.282339Z",
     "end_time": "2023-08-25T00:29:03.296433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "data = load_data('./googleplaystore.csv')\n",
    "x_train, x_test, y_train, y_test, x, y = split_data(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:29:03.298677Z",
     "end_time": "2023-08-25T00:29:03.505810Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf = 0.1392363876999213\n",
      "tree = 0.024856256268860122\n",
      "gradboost = 0.15049326719385048\n",
      "voting ensemble score: 0.14006841785330926\n"
     ]
    },
    {
     "data": {
      "text/plain": "'.//model_artifacts/model_voting.joblib'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type = 'voting'\n",
    "trained_model = train_model(x_train, y_train, x_test, y_test, type=type)\n",
    "save_model(trained_model, type=type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:30:32.498552Z",
     "end_time": "2023-08-25T00:30:38.022908Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging ensemble score: 0.11867157399190797\n"
     ]
    },
    {
     "data": {
      "text/plain": "'.//model_artifacts/model_bagging.joblib'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type = 'bagging'\n",
    "trained_model = train_model(x_train, y_train, x_test, y_test, type=type)\n",
    "save_model(trained_model, type=type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:30:38.017621Z",
     "end_time": "2023-08-25T00:30:38.716808Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking ensemble score: 0.15291239117867617\n"
     ]
    },
    {
     "data": {
      "text/plain": "'.//model_artifacts/model_stacking.joblib'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type = 'stacking'\n",
    "trained_model = train_model(x_train, y_train, x_test, y_test, type=type)\n",
    "save_model(trained_model, type=type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T00:30:18.695354Z",
     "end_time": "2023-08-25T00:30:32.496277Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
