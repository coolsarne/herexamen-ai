{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Student: Arne Cools - IAI3 - 2022/2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation & Hyperparameter Tuning\n",
    "## Part 2 - Model Evaluation & Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.feature_selection import f_regression, SelectPercentile\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from IPython.core.display_functions import display\n",
    "from sklearn.metrics import r2_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T23:35:55.098076Z",
     "end_time": "2023-08-24T23:35:55.119387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# First we make a method to return the processed dataset\n",
    "def categorize_price(price):\n",
    "    if price == 0:\n",
    "        return \"FREE\"\n",
    "    elif 0 < price < 5.0:\n",
    "        return \"CHEAP\"\n",
    "    else:\n",
    "        return \"EXPENSIVE\"\n",
    "\n",
    "def remove_outliers(df,columns,n_std):\n",
    "    for col in columns:\n",
    "\n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "\n",
    "        df = df[(df[col] <= mean+(n_std*sd))]\n",
    "\n",
    "    return df\n",
    "\n",
    "def return_dataset():\n",
    "    apps = pd.read_csv('../googleplaystore.csv')\n",
    "    apps['Reviews'] = pd.to_numeric(apps['Reviews'], errors='coerce')\n",
    "    apps['Size'] = apps['Size'].apply(lambda x: float(x.replace('k','')) / 1024 if 'k' in str(x) else x)  # Convert k to M\n",
    "    apps['Size'] = apps['Size'].apply(lambda x: None if x == 'Varies with device' else x) # Handles \"Varies with device\" values\n",
    "    apps['Size'] = apps['Size'].str.replace('M', '').str.replace('k', '').astype(float)\n",
    "    apps['Installs'] = apps['Installs'].str.replace('+', '').str.replace(',', '').astype('int64')\n",
    "    apps['Price'] = apps['Price'].str.replace('$', '').astype(float)\n",
    "    apps['Last Updated'] = pd.to_datetime(apps['Last Updated'])\n",
    "    apps = apps.drop_duplicates(subset='App', keep='first')\n",
    "    apps = remove_outliers(apps, ['Price'], 3)\n",
    "    apps = apps.dropna(subset=['Rating'])\n",
    "    apps['Size'] = apps['Size'].fillna(0)\n",
    "    encoder = LabelEncoder()\n",
    "    apps['Category_Encoded'] = encoder.fit_transform(apps['Category'])\n",
    "    apps['Content Rating_Encoded'] = encoder.fit_transform(apps['Content Rating'])\n",
    "    apps['Android Ver_Encoded'] = encoder.fit_transform(apps['Android Ver'])\n",
    "    current_date = pd.to_datetime('2019-01-01')  # All data is from before 2019\n",
    "    apps['Time Since Last Update'] = (current_date - apps['Last Updated']).dt.days\n",
    "    apps['App_Name_Length'] = apps['App'].apply(len)\n",
    "    apps['Price_Category_Labels'] = apps['Price'].apply(categorize_price)\n",
    "    apps['Price_Category_Encoded'] = apps['Price_Category_Labels'].map({'FREE': 0, 'CHEAP': 1, 'EXPENSIVE': 2})\n",
    "    numeric_columns = apps.select_dtypes(include=['number'])\n",
    "    numeric_columns = numeric_columns.drop(['Price'], axis=1)\n",
    "    apps = apps[numeric_columns.columns]\n",
    "    scaler = StandardScaler()\n",
    "    numeric_columns = ['Reviews', 'Size', 'Installs', 'Category_Encoded', 'Content Rating_Encoded','Android Ver_Encoded', 'Time Since Last Update', 'App_Name_Length', 'Price_Category_Encoded']\n",
    "    apps[numeric_columns] = scaler.fit_transform(apps[numeric_columns])\n",
    "    selector = SelectPercentile(score_func=f_regression, percentile=80)\n",
    "    X = selector.fit_transform(apps.select_dtypes(include=np.number), apps.Rating)\n",
    "    best_features = selector.get_support(indices=True)\n",
    "    apps = apps.select_dtypes(include=np.number).iloc[:, best_features]\n",
    "    return apps\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T20:54:14.699368Z",
     "end_time": "2023-08-24T20:54:14.746938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (5726, 7), (5726,)\n",
      "Test set: (2454, 7), (2454,)\n"
     ]
    }
   ],
   "source": [
    "apps = return_dataset()\n",
    "x = apps.drop('Rating', axis=1)\n",
    "y = apps.Rating\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print(f'Training set: {x_train.shape}, {y_train.shape}')\n",
    "print(f'Test set: {x_test.shape}, {y_test.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T20:54:18.335861Z",
     "end_time": "2023-08-24T20:54:18.555518Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.04\n",
      "Holdout Accuracy: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(x_train, y_train)\n",
    "\n",
    "print(f'Train Accuracy: {linear_model.score(x_train, y_train):.2f}')\n",
    "print(f'Holdout Accuracy: {linear_model.score(x_test, y_test):.2f}')\n",
    "\n",
    "# With a linear regression model I am only getting a 4% training accuracy and 3% testing accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T20:21:07.397165Z",
     "end_time": "2023-08-24T20:21:07.427847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Nearest Neighbors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbors - Holdout Accuracy: -0.80\n",
      "2 neighbors - Holdout Accuracy: -0.33\n",
      "3 neighbors - Holdout Accuracy: -0.20\n",
      "4 neighbors - Holdout Accuracy: -0.14\n",
      "5 neighbors - Holdout Accuracy: -0.11\n",
      "6 neighbors - Holdout Accuracy: -0.07\n",
      "7 neighbors - Holdout Accuracy: -0.04\n",
      "8 neighbors - Holdout Accuracy: -0.02\n",
      "9 neighbors - Holdout Accuracy: -0.01\n",
      "10 neighbors - Holdout Accuracy: -0.00\n",
      "11 neighbors - Holdout Accuracy: 0.01\n",
      "12 neighbors - Holdout Accuracy: 0.01\n",
      "13 neighbors - Holdout Accuracy: 0.02\n",
      "14 neighbors - Holdout Accuracy: 0.02\n",
      "15 neighbors - Holdout Accuracy: 0.02\n",
      "16 neighbors - Holdout Accuracy: 0.02\n",
      "17 neighbors - Holdout Accuracy: 0.03\n",
      "18 neighbors - Holdout Accuracy: 0.03\n",
      "19 neighbors - Holdout Accuracy: 0.03\n",
      "20 neighbors - Holdout Accuracy: 0.03\n",
      "21 neighbors - Holdout Accuracy: 0.03\n",
      "22 neighbors - Holdout Accuracy: 0.03\n",
      "23 neighbors - Holdout Accuracy: 0.04\n",
      "24 neighbors - Holdout Accuracy: 0.04\n",
      "25 neighbors - Holdout Accuracy: 0.04\n",
      "26 neighbors - Holdout Accuracy: 0.04\n",
      "27 neighbors - Holdout Accuracy: 0.05\n",
      "28 neighbors - Holdout Accuracy: 0.05\n",
      "29 neighbors - Holdout Accuracy: 0.05\n",
      "30 neighbors - Holdout Accuracy: 0.05\n",
      "31 neighbors - Holdout Accuracy: 0.05\n",
      "32 neighbors - Holdout Accuracy: 0.05\n",
      "33 neighbors - Holdout Accuracy: 0.05\n",
      "34 neighbors - Holdout Accuracy: 0.05\n",
      "35 neighbors - Holdout Accuracy: 0.05\n",
      "36 neighbors - Holdout Accuracy: 0.05\n",
      "37 neighbors - Holdout Accuracy: 0.05\n",
      "38 neighbors - Holdout Accuracy: 0.05\n",
      "39 neighbors - Holdout Accuracy: 0.05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1, 40):\n",
    "    neighbors_model = KNeighborsRegressor(n_neighbors=i)\n",
    "    neighbors_model.fit(x_train, y_train)\n",
    "    # print(f'{i} neighbors - Train Accuracy: {neighbors_model.score(x_train, y_train):.2f}')\n",
    "    print(f'{i} neighbors - Holdout Accuracy: {neighbors_model.score(x_test, y_test):.2f}')\n",
    "\n",
    "# As the number of neighbors (n_neighbors) increases, the model becomes less complex and tends to generalize better. This is evident from the decreasing accuracy scores for both the training and test sets. However, the decrease in the holdout R-squared values suggests that the model might be underfitting the data. We continue experimenting with other models\n",
    "\n",
    "# The bad results are not completely unexpected since k neigherst neighbors isn't fitted for categorical data because the distances have to mean something"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T20:21:11.297055Z",
     "end_time": "2023-08-24T20:21:16.801100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desicion Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 max nodes - Holdout Accuracy: 0.09\n",
      "10 max nodes - Holdout Accuracy: 0.09\n",
      "11 max nodes - Holdout Accuracy: 0.09\n",
      "12 max nodes - Holdout Accuracy: 0.09\n",
      "13 max nodes - Holdout Accuracy: 0.10\n",
      "14 max nodes - Holdout Accuracy: 0.10\n",
      "15 max nodes - Holdout Accuracy: 0.09\n",
      "16 max nodes - Holdout Accuracy: 0.10\n",
      "17 max nodes - Holdout Accuracy: 0.10\n",
      "18 max nodes - Holdout Accuracy: 0.10\n",
      "20 max nodes - Holdout Accuracy: 0.10\n",
      "21 max nodes - Holdout Accuracy: 0.09\n",
      "23 max nodes - Holdout Accuracy: 0.08\n",
      "24 max nodes - Holdout Accuracy: 0.08\n",
      "26 max nodes - Holdout Accuracy: 0.09\n",
      "28 max nodes - Holdout Accuracy: 0.10\n",
      "30 max nodes - Holdout Accuracy: 0.09\n",
      "32 max nodes - Holdout Accuracy: 0.09\n",
      "35 max nodes - Holdout Accuracy: 0.09\n",
      "37 max nodes - Holdout Accuracy: 0.09\n",
      "40 max nodes - Holdout Accuracy: 0.07\n",
      "43 max nodes - Holdout Accuracy: 0.06\n",
      "46 max nodes - Holdout Accuracy: 0.06\n",
      "49 max nodes - Holdout Accuracy: 0.05\n",
      "53 max nodes - Holdout Accuracy: 0.04\n",
      "57 max nodes - Holdout Accuracy: -0.02\n",
      "61 max nodes - Holdout Accuracy: -0.01\n",
      "65 max nodes - Holdout Accuracy: -0.05\n",
      "70 max nodes - Holdout Accuracy: -0.06\n",
      "75 max nodes - Holdout Accuracy: -0.07\n",
      "81 max nodes - Holdout Accuracy: -0.08\n",
      "86 max nodes - Holdout Accuracy: -0.10\n",
      "93 max nodes - Holdout Accuracy: -0.10\n",
      "100 max nodes - Holdout Accuracy: -0.11\n",
      "107 max nodes - Holdout Accuracy: -0.12\n",
      "114 max nodes - Holdout Accuracy: -0.12\n",
      "123 max nodes - Holdout Accuracy: -0.12\n",
      "132 max nodes - Holdout Accuracy: -0.12\n",
      "141 max nodes - Holdout Accuracy: -0.13\n",
      "151 max nodes - Holdout Accuracy: -0.16\n",
      "162 max nodes - Holdout Accuracy: -0.18\n",
      "174 max nodes - Holdout Accuracy: -0.19\n",
      "187 max nodes - Holdout Accuracy: -0.20\n",
      "200 max nodes - Holdout Accuracy: -0.22\n",
      "215 max nodes - Holdout Accuracy: -0.24\n",
      "231 max nodes - Holdout Accuracy: -0.26\n",
      "247 max nodes - Holdout Accuracy: -0.27\n",
      "265 max nodes - Holdout Accuracy: -0.29\n",
      "284 max nodes - Holdout Accuracy: -0.30\n",
      "305 max nodes - Holdout Accuracy: -0.32\n",
      "327 max nodes - Holdout Accuracy: -0.34\n",
      "351 max nodes - Holdout Accuracy: -0.35\n",
      "376 max nodes - Holdout Accuracy: -0.36\n",
      "403 max nodes - Holdout Accuracy: -0.36\n",
      "432 max nodes - Holdout Accuracy: -0.37\n",
      "464 max nodes - Holdout Accuracy: -0.39\n",
      "497 max nodes - Holdout Accuracy: -0.40\n",
      "533 max nodes - Holdout Accuracy: -0.40\n",
      "572 max nodes - Holdout Accuracy: -0.41\n",
      "613 max nodes - Holdout Accuracy: -0.42\n",
      "657 max nodes - Holdout Accuracy: -0.43\n",
      "705 max nodes - Holdout Accuracy: -0.45\n",
      "756 max nodes - Holdout Accuracy: -0.47\n",
      "811 max nodes - Holdout Accuracy: -0.49\n",
      "869 max nodes - Holdout Accuracy: -0.50\n",
      "932 max nodes - Holdout Accuracy: -0.51\n",
      "1000 max nodes - Holdout Accuracy: -0.52\n",
      "1072 max nodes - Holdout Accuracy: -0.52\n",
      "1149 max nodes - Holdout Accuracy: -0.54\n",
      "1232 max nodes - Holdout Accuracy: -0.56\n",
      "1321 max nodes - Holdout Accuracy: -0.56\n",
      "1417 max nodes - Holdout Accuracy: -0.57\n",
      "1519 max nodes - Holdout Accuracy: -0.57\n",
      "1629 max nodes - Holdout Accuracy: -0.58\n",
      "1747 max nodes - Holdout Accuracy: -0.59\n",
      "1873 max nodes - Holdout Accuracy: -0.60\n",
      "2009 max nodes - Holdout Accuracy: -0.61\n",
      "2154 max nodes - Holdout Accuracy: -0.62\n",
      "2310 max nodes - Holdout Accuracy: -0.63\n",
      "2477 max nodes - Holdout Accuracy: -0.63\n",
      "2656 max nodes - Holdout Accuracy: -0.63\n",
      "2848 max nodes - Holdout Accuracy: -0.64\n",
      "3053 max nodes - Holdout Accuracy: -0.64\n",
      "3274 max nodes - Holdout Accuracy: -0.65\n",
      "3511 max nodes - Holdout Accuracy: -0.65\n",
      "3764 max nodes - Holdout Accuracy: -0.65\n",
      "4037 max nodes - Holdout Accuracy: -0.65\n",
      "4328 max nodes - Holdout Accuracy: -0.65\n",
      "4641 max nodes - Holdout Accuracy: -0.65\n",
      "4977 max nodes - Holdout Accuracy: -0.65\n",
      "5336 max nodes - Holdout Accuracy: -0.65\n",
      "5722 max nodes - Holdout Accuracy: -0.65\n",
      "6135 max nodes - Holdout Accuracy: -0.65\n",
      "6579 max nodes - Holdout Accuracy: -0.65\n",
      "7054 max nodes - Holdout Accuracy: -0.65\n",
      "7564 max nodes - Holdout Accuracy: -0.65\n",
      "8111 max nodes - Holdout Accuracy: -0.65\n",
      "8697 max nodes - Holdout Accuracy: -0.65\n",
      "9326 max nodes - Holdout Accuracy: -0.65\n",
      "10000 max nodes - Holdout Accuracy: -0.65\n"
     ]
    }
   ],
   "source": [
    "leaf_node_sizes = np.logspace(1.0, 4.0, num=100, dtype=int)\n",
    "for max_leaf_nodes in leaf_node_sizes:\n",
    "    tree_model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    tree_model.fit(x_train, y_train)\n",
    "    #print(f'{max_leaf_nodes} max nodes - Train Accuracy: {tree_model.score(X_train, y_train):.2f}')\n",
    "    print(f'{max_leaf_nodes} max nodes - Holdout Accuracy: {tree_model.score(x_test, y_test):.2f}')\n",
    "\n",
    "\n",
    "# With an accuracy of 6% we have a better model than the above, but it's still not good enough to work with."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T23:36:11.373994Z",
     "end_time": "2023-08-24T23:36:15.916771Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest\n",
    "Random forests can handle both categorical and numeric features well. They can capture complex interactions between features and handle nonlinearity. Random forests tend to perform well out of the box and are less prone to overfitting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : -0.6780580272053938\n",
      "2 : -0.36559306813578374\n",
      "3 : -0.12759913440991122\n",
      "4 : -0.11542030644210177\n",
      "5 : -0.02115803284364448\n",
      "6 : 0.007488000008954887\n",
      "7 : 1.3929689003933099e-05\n",
      "8 : 0.03689938282229521\n",
      "9 : 0.013832539539511246\n",
      "10 : 0.030842792275967423\n",
      "11 : 0.047245624504731354\n",
      "12 : 0.04097104781494221\n",
      "13 : 0.053236051224179515\n",
      "14 : 0.06488154037867211\n",
      "15 : 0.04261480891155478\n",
      "16 : 0.06934529909275311\n",
      "17 : 0.06487502497763786\n",
      "18 : 0.05969882256159598\n",
      "19 : 0.09740667520610025\n",
      "20 : 0.07452636961296077\n",
      "21 : 0.08895012566419613\n",
      "22 : 0.09156929072416542\n",
      "23 : 0.08068089454132044\n",
      "24 : 0.06359326253479303\n",
      "25 : 0.09653188696662096\n",
      "26 : 0.08383793981628163\n",
      "27 : 0.10265218989703462\n",
      "28 : 0.09034149229909938\n",
      "29 : 0.1002848586596019\n",
      "30 : 0.09937355178341978\n",
      "31 : 0.12087350374527217\n",
      "32 : 0.10609874284962106\n",
      "33 : 0.11020095938849472\n",
      "34 : 0.10402216060281189\n",
      "35 : 0.10944067187518591\n",
      "36 : 0.10681013559283081\n",
      "37 : 0.08866291025675255\n",
      "38 : 0.09576869263888999\n",
      "39 : 0.10880784465262672\n",
      "40 : 0.10164567541260505\n",
      "41 : 0.10400979583397618\n",
      "42 : 0.10106659981585309\n",
      "43 : 0.0962039933242157\n",
      "44 : 0.11784708610678518\n",
      "45 : 0.09930724326374707\n",
      "46 : 0.1110654928295488\n",
      "47 : 0.11775949278825504\n",
      "48 : 0.09598584121942377\n",
      "49 : 0.10197622646687987\n",
      "50 : 0.09874595485092585\n",
      "51 : 0.11542222541555014\n",
      "52 : 0.11912735849957479\n",
      "53 : 0.09891355336994045\n",
      "54 : 0.10165791486044173\n",
      "55 : 0.10605987468839728\n",
      "56 : 0.11124694601746532\n",
      "57 : 0.10898164825367296\n",
      "58 : 0.11453653466017644\n",
      "59 : 0.12111757955988545\n",
      "60 : 0.10249882966961699\n",
      "61 : 0.09992681154848482\n",
      "62 : 0.12896531074688533\n",
      "63 : 0.11207388290306053\n",
      "64 : 0.11010191664499258\n",
      "65 : 0.10143956479974259\n",
      "66 : 0.11656222561058771\n",
      "67 : 0.11274502323388291\n",
      "68 : 0.10705740406081321\n",
      "69 : 0.12217804633741292\n",
      "70 : 0.10261708773793954\n",
      "71 : 0.12111958243487309\n",
      "72 : 0.11371414380923994\n",
      "73 : 0.11999294017711792\n",
      "74 : 0.1250016844454609\n",
      "75 : 0.11719181305943038\n",
      "76 : 0.1070090432092774\n",
      "77 : 0.10855400769564372\n",
      "78 : 0.11773644870312949\n",
      "79 : 0.11655826797396673\n",
      "80 : 0.10792264910992444\n",
      "81 : 0.10033625182694528\n",
      "82 : 0.11947600103926825\n",
      "83 : 0.12820145311015685\n",
      "84 : 0.10458267799372722\n",
      "85 : 0.10702825202471677\n",
      "86 : 0.11770458686248342\n",
      "87 : 0.1190591316527213\n",
      "88 : 0.10874459529653968\n",
      "89 : 0.12354630696298163\n",
      "90 : 0.11565994229394205\n",
      "91 : 0.1258382785879678\n",
      "92 : 0.12521663518721982\n",
      "93 : 0.1253498917102085\n",
      "94 : 0.1179890750980882\n",
      "95 : 0.11935907528813328\n",
      "96 : 0.11281106855246192\n",
      "97 : 0.11172229296046454\n",
      "98 : 0.1257093585212249\n",
      "99 : 0.10185442079028217\n"
     ]
    }
   ],
   "source": [
    "for t in range(1,100):\n",
    "    rf_model = RandomForestRegressor(n_estimators=t)\n",
    "    rf_model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "\n",
    "    print(f\"{t} : {rf_model.score(x_test, y_test)}\")\n",
    "\n",
    "# with an accuracy of 12.5% on 93 trees this is the best model so far"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T20:23:44.025281Z",
     "end_time": "2023-08-24T20:30:27.580243Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15084172173541377\n"
     ]
    }
   ],
   "source": [
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "gb_regressor.fit(x_train, y_train)\n",
    "\n",
    "print(f\"{gb_regressor.score(x_test, y_test)}\")\n",
    "\n",
    "# Another better model then before with 15%"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T20:40:59.739346Z",
     "end_time": "2023-08-24T20:41:01.005945Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03924091345193914\n"
     ]
    }
   ],
   "source": [
    "svr_model = SVR(kernel='linear')  # You can try different kernels ('precomputed', 'linear', 'rbf', 'poly', 'sigmoid')\n",
    "svr_model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"{svr_model.score(x_test, y_test)}\")\n",
    "\n",
    "# After trying several different kernels, 3% was the best accuracy I could get out of it\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T20:16:48.484786Z",
     "end_time": "2023-08-24T20:17:06.967611Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Model Selection\n",
    "We will work with the models that gave us somewhat decent results: Random Forest and Gradient Boosting\n",
    "\n",
    "To make a further selection I will use cross validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-Fold Cross-Validation Accuracy GB Model: 0.13 (+/- 0.03)\n",
      "6-Fold Cross-Validation Accuracy RF Model: 0.08 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=93)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "gb_scores = cross_val_score(gb_model, x, y, cv=6)\n",
    "rf_scores = cross_val_score(rf_model, x, y, cv=6)\n",
    "print(f'6-Fold Cross-Validation Accuracy GB Model: {gb_scores.mean():.2f} (+/- {gb_scores.std():.2f})')\n",
    "print(f'6-Fold Cross-Validation Accuracy RF Model: {rf_scores.mean():.2f} (+/- {rf_scores.std():.2f})')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:06:59.412239Z",
     "end_time": "2023-08-24T21:07:51.924079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   fit_time  score_time  test_score  train_score\n0  1.115609    0.004342    0.069506     0.258293\n1  1.023162    0.002735    0.147638     0.253997\n2  1.007517    0.003248    0.179756     0.255011\n3  1.010035    0.003117    0.109422     0.280144\n4  1.048788    0.002744    0.131074     0.271240\n5  1.012796    0.003284    0.122572     0.268184",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.115609</td>\n      <td>0.004342</td>\n      <td>0.069506</td>\n      <td>0.258293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.023162</td>\n      <td>0.002735</td>\n      <td>0.147638</td>\n      <td>0.253997</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.007517</td>\n      <td>0.003248</td>\n      <td>0.179756</td>\n      <td>0.255011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.010035</td>\n      <td>0.003117</td>\n      <td>0.109422</td>\n      <td>0.280144</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.048788</td>\n      <td>0.002744</td>\n      <td>0.131074</td>\n      <td>0.271240</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.012796</td>\n      <td>0.003284</td>\n      <td>0.122572</td>\n      <td>0.268184</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_scores = cross_validate(gb_model, x, y, cv=6, return_train_score=True)\n",
    "pd.DataFrame(gb_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:07:56.110424Z",
     "end_time": "2023-08-24T21:08:02.421346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   fit_time  score_time  test_score  train_score\n0  7.121891    0.026790    0.016377     0.879056\n1  6.450706    0.022077    0.034239     0.877813\n2  6.878714    0.026408    0.166155     0.877349\n3  6.702561    0.047703    0.038693     0.883215\n4  6.524832    0.024896    0.097238     0.878812\n5  6.526302    0.026547    0.084213     0.878473",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.121891</td>\n      <td>0.026790</td>\n      <td>0.016377</td>\n      <td>0.879056</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.450706</td>\n      <td>0.022077</td>\n      <td>0.034239</td>\n      <td>0.877813</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.878714</td>\n      <td>0.026408</td>\n      <td>0.166155</td>\n      <td>0.877349</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6.702561</td>\n      <td>0.047703</td>\n      <td>0.038693</td>\n      <td>0.883215</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.524832</td>\n      <td>0.024896</td>\n      <td>0.097238</td>\n      <td>0.878812</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6.526302</td>\n      <td>0.026547</td>\n      <td>0.084213</td>\n      <td>0.878473</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_scores = cross_validate(rf_model, x, y, cv=6, return_train_score=True)\n",
    "pd.DataFrame(rf_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:08:08.017970Z",
     "end_time": "2023-08-24T21:08:49.108956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-Fold Cross-Validation Accuracy GB Model: 0.15 (+/- 0.03)\n",
      "6-Fold Cross-Validation Accuracy RF Model: 0.13 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross-Validation\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=93)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True)\n",
    "gb_scores = cross_val_score(gb_model, x, y, cv=kf)\n",
    "rf_scores = cross_val_score(rf_model, x, y, cv=kf)\n",
    "print(f'6-Fold Cross-Validation Accuracy GB Model: {gb_scores.mean():.2f} (+/- {gb_scores.std():.2f})')\n",
    "print(f'6-Fold Cross-Validation Accuracy RF Model: {rf_scores.mean():.2f} (+/- {rf_scores.std():.2f})')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:08:49.112093Z",
     "end_time": "2023-08-24T21:09:43.938909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   fit_time  score_time  test_score  train_score\n0  1.167594    0.005146    0.069506     0.258293\n1  1.110326    0.002868    0.147638     0.253997\n2  1.334771    0.003204    0.179756     0.255011\n3  1.105913    0.002734    0.107601     0.280144\n4  1.081942    0.003272    0.131574     0.271240\n5  1.050316    0.003351    0.119276     0.268184",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.167594</td>\n      <td>0.005146</td>\n      <td>0.069506</td>\n      <td>0.258293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.110326</td>\n      <td>0.002868</td>\n      <td>0.147638</td>\n      <td>0.253997</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.334771</td>\n      <td>0.003204</td>\n      <td>0.179756</td>\n      <td>0.255011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.105913</td>\n      <td>0.002734</td>\n      <td>0.107601</td>\n      <td>0.280144</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.081942</td>\n      <td>0.003272</td>\n      <td>0.131574</td>\n      <td>0.271240</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.050316</td>\n      <td>0.003351</td>\n      <td>0.119276</td>\n      <td>0.268184</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_scores = cross_validate(gb_model, x, y, cv=6, return_train_score=True)\n",
    "pd.DataFrame(gb_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:09:43.940459Z",
     "end_time": "2023-08-24T21:09:50.897034Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   fit_time  score_time  test_score  train_score\n0  6.914356    0.025474    0.015448     0.880333\n1  6.842549    0.022966    0.022423     0.877533\n2  7.039722    0.036020    0.165204     0.879229\n3  7.066803    0.024077    0.048889     0.880021\n4  6.648202    0.025631    0.112954     0.878893\n5  6.340713    0.035141    0.080061     0.878171",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.914356</td>\n      <td>0.025474</td>\n      <td>0.015448</td>\n      <td>0.880333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.842549</td>\n      <td>0.022966</td>\n      <td>0.022423</td>\n      <td>0.877533</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.039722</td>\n      <td>0.036020</td>\n      <td>0.165204</td>\n      <td>0.879229</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.066803</td>\n      <td>0.024077</td>\n      <td>0.048889</td>\n      <td>0.880021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.648202</td>\n      <td>0.025631</td>\n      <td>0.112954</td>\n      <td>0.878893</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6.340713</td>\n      <td>0.035141</td>\n      <td>0.080061</td>\n      <td>0.878171</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_scores = cross_validate(rf_model, x, y, cv=6, return_train_score=True)\n",
    "pd.DataFrame(rf_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:09:50.900347Z",
     "end_time": "2023-08-24T21:10:32.582503Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since I am looking for a model that gives me the most accurate predictions, I am mostly looking at the 'test_score' column because this shows how well the model performs on a dataset where it's not trained on.\n",
    "I will therefore choose the Gradient Boosting Regressor model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('poly', PolynomialFeatures()),\n                ('gradboost', GradientBoostingRegressor())])",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n                (&#x27;gradboost&#x27;, GradientBoostingRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n                (&#x27;gradboost&#x27;, GradientBoostingRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([('poly', PolynomialFeatures()),\n",
    "                  ('gradboost', GradientBoostingRegressor())])\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:27:14.261033Z",
     "end_time": "2023-08-24T21:27:14.298202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "      degree  include_bias  interaction_only order\npoly       2          True             False     C",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>degree</th>\n      <th>include_bias</th>\n      <th>interaction_only</th>\n      <th>order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>poly</th>\n      <td>2</td>\n      <td>True</td>\n      <td>False</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "           alpha  ccp_alpha     criterion  init  learning_rate           loss  \\\ngradboost    0.9        0.0  friedman_mse  None            0.1  squared_error   \n\n           max_depth max_features max_leaf_nodes  min_impurity_decrease  ...  \\\ngradboost          3         None           None                    0.0  ...   \n\n           min_samples_split  min_weight_fraction_leaf  n_estimators  \\\ngradboost                  2                       0.0           100   \n\n           n_iter_no_change random_state subsample     tol  \\\ngradboost              None         None       1.0  0.0001   \n\n           validation_fraction  verbose  warm_start  \ngradboost                  0.1        0       False  \n\n[1 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alpha</th>\n      <th>ccp_alpha</th>\n      <th>criterion</th>\n      <th>init</th>\n      <th>learning_rate</th>\n      <th>loss</th>\n      <th>max_depth</th>\n      <th>max_features</th>\n      <th>max_leaf_nodes</th>\n      <th>min_impurity_decrease</th>\n      <th>...</th>\n      <th>min_samples_split</th>\n      <th>min_weight_fraction_leaf</th>\n      <th>n_estimators</th>\n      <th>n_iter_no_change</th>\n      <th>random_state</th>\n      <th>subsample</th>\n      <th>tol</th>\n      <th>validation_fraction</th>\n      <th>verbose</th>\n      <th>warm_start</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>gradboost</th>\n      <td>0.9</td>\n      <td>0.0</td>\n      <td>friedman_mse</td>\n      <td>None</td>\n      <td>0.1</td>\n      <td>squared_error</td>\n      <td>3</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>100</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1.0</td>\n      <td>0.0001</td>\n      <td>0.1</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                    key  \\\n0                                memory   \n1                                 steps   \n2                               verbose   \n3                                  poly   \n4                             gradboost   \n5                          poly__degree   \n6                    poly__include_bias   \n7                poly__interaction_only   \n8                           poly__order   \n9                      gradboost__alpha   \n10                 gradboost__ccp_alpha   \n11                 gradboost__criterion   \n12                      gradboost__init   \n13             gradboost__learning_rate   \n14                      gradboost__loss   \n15                 gradboost__max_depth   \n16              gradboost__max_features   \n17            gradboost__max_leaf_nodes   \n18     gradboost__min_impurity_decrease   \n19          gradboost__min_samples_leaf   \n20         gradboost__min_samples_split   \n21  gradboost__min_weight_fraction_leaf   \n22              gradboost__n_estimators   \n23          gradboost__n_iter_no_change   \n24              gradboost__random_state   \n25                 gradboost__subsample   \n26                       gradboost__tol   \n27       gradboost__validation_fraction   \n28                   gradboost__verbose   \n29                gradboost__warm_start   \n\n                                                value  \n0                                                None  \n1   [(poly, PolynomialFeatures()), (gradboost, Gra...  \n2                                               False  \n3                                PolynomialFeatures()  \n4                         GradientBoostingRegressor()  \n5                                                   2  \n6                                                True  \n7                                               False  \n8                                                   C  \n9                                                 0.9  \n10                                                0.0  \n11                                       friedman_mse  \n12                                               None  \n13                                                0.1  \n14                                      squared_error  \n15                                                  3  \n16                                               None  \n17                                               None  \n18                                                0.0  \n19                                                  1  \n20                                                  2  \n21                                                0.0  \n22                                                100  \n23                                               None  \n24                                               None  \n25                                                1.0  \n26                                             0.0001  \n27                                                0.1  \n28                                                  0  \n29                                              False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>memory</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>steps</td>\n      <td>[(poly, PolynomialFeatures()), (gradboost, Gra...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>verbose</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>poly</td>\n      <td>PolynomialFeatures()</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gradboost</td>\n      <td>GradientBoostingRegressor()</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>poly__degree</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>poly__include_bias</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>poly__interaction_only</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>poly__order</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>gradboost__alpha</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>gradboost__ccp_alpha</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>gradboost__criterion</td>\n      <td>friedman_mse</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>gradboost__init</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>gradboost__learning_rate</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>gradboost__loss</td>\n      <td>squared_error</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>gradboost__max_depth</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>gradboost__max_features</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>gradboost__max_leaf_nodes</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>gradboost__min_impurity_decrease</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>gradboost__min_samples_leaf</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>gradboost__min_samples_split</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>gradboost__min_weight_fraction_leaf</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>gradboost__n_estimators</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>gradboost__n_iter_no_change</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>gradboost__random_state</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>gradboost__subsample</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>gradboost__tol</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>gradboost__validation_fraction</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>gradboost__verbose</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>gradboost__warm_start</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters\n",
    "display(pd.DataFrame(model['poly'].get_params(), index=['poly']))\n",
    "display(pd.DataFrame(model['gradboost'].get_params(), index=['gradboost']))\n",
    "pd.set_option('display.max_rows', None)\n",
    "#hyperparameters\n",
    "pd.DataFrame([model.get_params().keys(), model.get_params().values()], index=['key', 'value']).T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T21:28:20.927695Z",
     "end_time": "2023-08-24T21:28:20.988913Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Hyperparameters I will tune are: \"poly__degree\", \"gradboost__criterion\", \"gradboost__max_depth\", \"gradboost__n_estimators\"\n",
    "\n",
    "poly__degree = determines the degree of the polynomial\n",
    "gradboost__max_depth = Maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree.\n",
    "gradboost__n_estimators = The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('poly', PolynomialFeatures()),\n                ('gradboost',\n                 GradientBoostingRegressor(max_depth=5, n_estimators=30))])",
      "text/html": "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n                (&#x27;gradboost&#x27;,\n                 GradientBoostingRegressor(max_depth=5, n_estimators=30))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n                (&#x27;gradboost&#x27;,\n                 GradientBoostingRegressor(max_depth=5, n_estimators=30))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=5, n_estimators=30)</pre></div></div></div></div></div></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    # 'poly__degree': [3,5],\n",
    "    'gradboost__max_depth': [1,3,5,10,15,30,50],\n",
    "    'gradboost__n_estimators':[i * 10 for i in range(1, 12, 2)]\n",
    "}\n",
    "\n",
    "randomsearch = RandomizedSearchCV(model, hyperparameters, cv=5, n_iter=5, verbose=1, n_jobs= -1, )\n",
    "randomsearch.fit(x, y)\n",
    "display(randomsearch.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T22:49:01.417061Z",
     "end_time": "2023-08-24T23:01:17.177421Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "0.31341848958472107"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y, randomsearch.best_estimator_.predict(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T23:07:11.442037Z",
     "end_time": "2023-08-24T23:07:11.490236Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With a Random Search we find that we get the best model with max_depth = 5 and n_estimators = 30 with an r2 score of 31%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 42 candidates, totalling 84 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('poly', PolynomialFeatures()),\n                ('gradboost', GradientBoostingRegressor(n_estimators=110))])",
      "text/html": "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n                (&#x27;gradboost&#x27;, GradientBoostingRegressor(n_estimators=110))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n                (&#x27;gradboost&#x27;, GradientBoostingRegressor(n_estimators=110))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=110)</pre></div></div></div></div></div></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    # 'poly__degree': [3,5],\n",
    "    'gradboost__max_depth': [1,3,5,10,15,30,50],\n",
    "    'gradboost__n_estimators':[i * 10 for i in range(1, 12, 2)]\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(model, hyperparameters, cv=4, verbose=1, n_jobs=-1)\n",
    "gridsearch.fit(x, y)\n",
    "display(gridsearch.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T23:44:58.846173Z",
     "end_time": "2023-08-24T23:49:05.806244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2920558451469526"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y, gridsearch.best_estimator_.predict(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T23:49:32.547617Z",
     "end_time": "2023-08-24T23:49:32.600444Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With a Grid Search we find that we get the best model with max_depth = 5 and n_estimators = 110 with an r2 score of 29%"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
